---
title: "Final Project"
author: "Alicia Helfrich, Olivia Gomez, and Akbar Naqvi"
format: html
editor: visual
embed-resources: true
---

Outline from meeting:

-   Lit review

-   Overview of data sources

-   Exploratory Data Analysis and Data Cleaning

-   Building Models

-   Analyzing results - variable importance

-   Conclusion Limitations

-   download file for data folder: (Data and Documents - Primary Data File) link: https://www.census.gov/programs-surveys/sipp/data/datasets/2019-data/2019.html Download the Pipe-Delimited Text Format version to read in a CSV

## Project Overview

### Introduction

The Patient Protection and Affordable Care Act (ACA), passed in 2010, increased access to health insurance coverage for over 20 million Americans. Yet in 2022, over 25 million Americans still did not have health insurance (KFF). Being uninsured has been shown to lead to poorer health outcomes, limited preventative care, and increased risk of mortality (NILC). Uninsurance is also associated with poor economic outcomes and increases general costs for employers, taxpayers, health systems, and the general public (Commonwealth). For example, uncompensated care for those without insurance averaged over \$42 billion between 2015 and 2017 (KFF).

Losing insurance can happen for a multitude of reasons, such as job loss or a change in eligibility for public insurance programs. However, getting people reenrolled in insurance can be difficult due to lack of knowledge of available programs and financial assistance, high cost of insurance, and availability (e.g. coverage offered through employment) (KFF). Due to the high social and economic costs associated with being uninsured, state and federal governments, non-profit organizations, and other interested stakeholders have launched campaigns to raise awareness on financial assistance programs, tax credits, state-based Marketplace exchanges, and Medicaid eligibility (Commonwealth). Given that the uninsured population is made up of over 25 million people, targeting campaigns can save taxpayer dollars and increase the effectiveness of the programs.

https://www.kff.org/uninsured/issue-brief/key-facts-about-the-uninsured-population/

https://www.nilc.org/wp-content/uploads/2015/11/consequences-of-being-uninsured-2014-08.pdf

https://www.commonwealthfund.org/sites/default/files/documents/\_\_\_media_files_publications_in_the_literature_2003_jun_the_costs_and_consequences_of_being_uninsured_davis_consequences_itl_663_pdf.pdf

https://www.kff.org/uninsured/issue-brief/sources-of-payment-for-uncompensated-care-for-the-uninsured/

https://www.commonwealthfund.org/publications/issue-briefs/2022/oct/state-based-outreach-boosting-enrollment-uninsured

### Methodology

Using supervised machine learning techniques and the Survey of Income and Participation Data, we developed a model to predict the likelihood that a Medicaid beneficiary will churn out of the program during the course of a year; in other words, if they lose eligibility and are terminated from the program. While the main eligibility guideline for Medicaid is income, we believe that utilizing other demographic factors can be a helpful predictor of churn. Such a predictive model can help states reduce churn by targeting outreach and enrollment activities of states. For example, it may be in a state's best interest to target enrollment campaigns for other public insurance programs towards population groups of interest. This can ensure everyone who is eligible has access to the program, and can enroll people into other public programs (like a Marketplace plan) if they are eligible. Reducing the uninsured population can reduce health care costs for states.

As mentioned before, states have different eligibility rules and guidelines. For example, three states allow for 12-month continuous eligibility, while others conduct periodic eligibility checks before the standard annual renewal date. To account for some of these variations, we have created several indicator variables.

Sources of state eligibility variables: - (KFF tables - https://www.kff.org/report-section/medicaid-and-chip-eligibility-enrollment-and-cost-sharing-policies-as-of-january-2020-findings-from-a-50-state-survey-tables/) - (Commonwealth - https://www.commonwealthfund.org/publications/issue-briefs/2023/sep/ensuring-continuous-eligibility-medicaid-impacts-adults)

Using supervised machine learning techniques and data from the Survey of Income and Participation (SIPP), we developed a model to predict the likelihood that a person would lose health insurance in the course of a year. Such a predictive model can help state and federal policymakers and other interested stakeholders target outreach and enrollment activities For example, it may be in a state's best interest to target enrollment campaigns for public insurance programs towards population groups of interest. As discussed, reducing the uninsured population can reduce health care costs for states and the federal government.

## Data Sources

The Survey of Income and Program Participation (SIPP) is an extensive survey conducted by the U.S. Census Bureau. It contains data on income, labor force participation, social program participation and eligibility, and general demographic characteristics. We are using the SIPP given its breadth, detail, and inclusion of health insurance status. We are using data from the year 2019, which was the last full year before the start of the COVID-19 pandemic and three full years of continuous eligibility in Medicaid. Using data after 2019 would not allow us to accurately examine churn. It is important to note that survey parti

Survey participants provide data for each month in the preceding calendar year at the time of the interview. Because of this detail, observations are on the person-month level, meaning there could be 12 observations for a single person for a given variable. Household-level questions are copied across all members of the household.

```{r}

library(tidyverse)
library(haven)
library(data.table)
library(readxl)
library(lubridate)
library(vcd)

```

### Reading in Data

```{r, cache=TRUE, cache.id="data_pull"}

#initial pull of data
data_2018 <- fread("data/pu2018.csv", 
                   sep = "|",
                   showProgress = TRUE) %>% 
            select(-starts_with("A"))


names(data_2019) <- toupper(names(data_2018))
#Make sure all the column names are upper-case
```

Weights

```{r}

rw_2019 <- fread("data/rw2019.csv", 
                   sep = "|",
                   showProgress = TRUE)
#Read in the replicate-weight data. This dataset is small enough that most machines
#	can read the whole file into memory

names(rw_2019) <- toupper(names(rw_2019))
#Make sure all the column names are upper-case


data_2019 <- left_join(data_2019, rw_2019, by = c("SSUID","PNUM","MONTHCODE"))
#Merge primary data and replicate weights on SSUID, PNUM, MONTHCODE, SPANEL, and SWAVE

```

Cleaning

```{r}

data_2019 <- data_2019 %>%
    select(-starts_with("A")) # these are status flags of all variables

data_2018 <- data_2018 %>% 
   #make unique ID for each respondent
  mutate(unique_id = paste(SSUID,PNUM))
  
```

#Insurance Loss Coding

```{r}
#processing outcome variable - individuals covered by medicaid that experienced a gap in coverage during 2019
lost_insurance_detail <- data_2018 %>%
  
  select(SPANEL,SSUID,SWAVE,PNUM,MONTHCODE,RHLTHMTH) %>% 
  
    #make unique ID for each respondent
  mutate(unique_id = paste(SSUID,PNUM))

#creating variables to assess if someone lost medicaid from one quarter to the next
lost_insurance_prep <- lost_insurance_detail %>% 
  arrange(unique_id,MONTHCODE) %>% 
  group_by(unique_id) %>% 
    mutate(
      #recode health insurance bulean to be "no_insurance"
      no_insurance = case_when(
        RHLTHMTH == 2 ~ 1, #had no coverage whatsoever
        RHLTHMTH == 1 ~ 0 #had coverage
      ),
     
      #create field of "no_insurance_last_month" for each observation
      no_insurance_last_month = lag(no_insurance),
      
      #create variable subtracting no_insurace and no_insurance last month
      # values will = 1 when they had insurance last month,  but didn't this
      lost_insurance = no_insurance - no_insurance_last_month,
     
      insurance_gap = case_when(
        lost_insurance > 0  ~ 1,
        lost_insurance <= 0 ~ 0),
     
      #rename month columns
      month = case_when(
        MONTHCODE == 1 ~ "January",
        MONTHCODE == 2 ~ "February",
        MONTHCODE == 3 ~ "March",
        MONTHCODE == 4 ~ "April",
        MONTHCODE == 5 ~ "May",
        MONTHCODE == 6 ~ "June",
        MONTHCODE == 7 ~ "July",
        MONTHCODE == 8 ~ "August",
        MONTHCODE == 9 ~ "September",
        MONTHCODE == 10 ~ "October",
        MONTHCODE == 11 ~ "November",
        MONTHCODE == 12 ~ "December")
    )
  
    
    #create data frame of unique individuals that had medicaid at some point of the year
      #will use to filter the lost_medicaid_prep 
      insurance_gap <-  lost_insurance_prep %>% 
        pivot_wider(
      id_cols = unique_id, 
      names_from = month,
      values_from = insurance_gap) %>% 
        #column to assess if someone had medicaid
        mutate(
       month_of_insurance_loss = sum(January,February, March, April, May, June, July, August, September, October, November, December, na.rm = TRUE),
        insurance_gap = case_when(
          month_of_insurance_loss > 0 ~ 1,
          month_of_insurance_loss < 1 ~ 0)
        )
    
      data_2018_final <- insurance_gap %>% 
        left_join(
          x = .,
          y = data_2018,
          by = "unique_id"
        ) %>% 
         distinct(unique_id, .keep_all = TRUE)
      
    
```


##Medicaid Eligibility Variables
```{r}


# tibble of indicator variables for state eligibility rules of interest
state_eligibility_rules <- read_excel("data/state_eligibility_rules.xlsx")
  
data_2018_final <-  data_2018_final %>% 
  mutate( state_id = TEHC_ST) %>% 
        left_join(
          x = .,
          y = state_eligibility_rules,
          by = "state_id"
        )

```

## Exploratory Data Analysis

### missingness (Akbar)

The SIPP uses two imputation methods based on the assumption that data are missing at random within subgroups of the population. The imputation methods used are:

1.  Model-based Imputation: A process that involves estimating sequential models that predict values for a missing variable, conditional on demographic data, all other topic flags earnings data within the IRS and SSA.
2.  Sequential hot-deck imputation: This method matches a record with missing data to that of a donor with similar background characteristics

-   describe why we are leaving missinging as is, since they did imputation on thier own
-   explain missing variables in olivia's data

### correlation (Alicia)

```{r}

# evaluating correlation
potential_predictors <- data_2018_final %>%
  ungroup() %>% 
  
  select(insurance_gap,
         
         # all employment data
         starts_with("EJB"),
         
         # medicaid eligibility
         starts_with("elig_"),
         
         #adult wellbeing
         starts_with("EAWB"),
         
         #food security
         starts_with("EFOOD"),
         
         #demographics
         TAGE_EHC,#Age
         RFAMKIND,#family size
         RFRELU18,RHNUM65OVER,
         EORIGIN,EMS,ECITIZEN,#country of origin
         EHOWWELL,ERACE,ESEX,#engligh proficiency,race,sex
         RFOODS, #food security
         RDIS, #disability status
         EMS, #marital status
         
         #personal finances
         TDEBT_AST, #personal debt
         THINC_AST,#household income
         TNETWORTH, #net worth
         
         #location
         EAWBSAFE, #safety
         EVOUCHER, #housing voucher
         TEHC_ST, #state
         TMETRO_INTV, #metropolitan area
  )

potential_predictors_num <- potential_predictors %>% 
  select(where(is.numeric))
        
# Calculate correlation matrix
correlation_matrix <- cor(potential_predictors_num,use = "pairwise.complete.obs")

# Filter correlations above 0.5
insurance_gap_correlations <- correlation_matrix["insurance_gap", ]

# Filter correlations greater than 0.5 or less than -0.5
significant_correlations <-  insurance_gap_correlations[order(abs(insurance_gap_correlations),decreasing = TRUE)] 

significant_correlations <- 
    significant_correlations[!is.na(significant_correlations)] %>% 
    head(200)

significant_correlations <- enframe(significant_correlations,name = "variable",value = "correlation_level")

significant_correlations_names <- significant_correlations %>% 
  as_tibble() %>% 
  select(variable) %>% 
  pull(variable)

```

### limit training/testing dataset to only include the most significant predictors

```{r}

data_2018_final_test <- data_2018_final %>% 
  select(unique_id,
         all_of(significant_correlations_names))
  
```

### explore categorical variables of interest (Alicia - depending on Aaron's response)

-   review of categorical variables and see if there is anything crazy

## Predictive Modeling

-   Describing the selection of variables

```{r}

## Alicia's feature engineering example for the random forest model from assignment 7 

rf_rec <- recipe(non_return_rate ~ ., training) %>% 
  ## remove categorical variables with many categories
    update_role(state_name, county_name,low_response_score,gidtr, 
                 pct_tea_update_leave_cen_2010, new_role = "id") %>%
      step_rm(has_role("id")) %>%
  ## impute missing values
  step_impute_mean(all_numeric_predictors()) 
 
```

-   see if any variables are 100% missing once we drop to Medicaid and January
-   look out for allocation flags (if it was imputed), status flags all start with A
-   consider dropping and picking key variables in each issue area
-   seam mismatch

## Analyzing Results

Building the model

```{r}

vars <- "variables"
id_vars <- "id_variables"

rf_rec <- recipe(non_return_rate ~ vars., data_2019) |>
  add_role(id_vars, new_role = "id") |>
  step_rm(has_role("id"))

# we selected these hyperparameters with tuning and cross validation
rf_mod <- rand_forest(
  trees = 200,
  mtry = 11,
  min_n = 4
) |>
  set_mode(mode = "regression") |>
  set_engine(
    engine = "ranger", 
    importance = "impurity",
    num.threads = 4
  )

rf_wf <- workflow() |>
  add_recipe(rf_rec) |>
  add_model(rf_mod)

rf_resamples <- rf_wf |>
  fit_resamples(resamples = pdb_folds)

rf_resamples |>
  collect_metrics()

```

Variable importance

```{r}

rf_final <- rf_wf |>
  last_fit(pdb_split) 

rf_final |>
  extract_fit_parsnip() |>
  vip(num_features = 20) 

```

-   precision versus accuracy - justify error metric - Akbar
-   Variable Important

## Conclusions and Limitations

-   Conclusions and limitations text

---
title: "Final Project"
author: "Alicia Helfrich, Olivia Gomez, and Akbar Naqvi"
format: html
editor: visual
embed-resources: true
---

Outline from meeting:

-   Lit review

-   Overview of data sources

-   Exploratory Data Analysis and Data Cleaning

-   Building Models

-   Analyzing results - variable importance

-   Conclusion Limitations

-   download file for data folder: (Data and Documents - Primary Data File) link: https://www.census.gov/programs-surveys/sipp/data/datasets/2019-data/2019.html Download the Pipe-Delimited Text Format version to read in a CSV

## Project Overview

### Introduction

The Patient Protection and Affordable Care Act (ACA), passed in 2010, increased access to health insurance coverage for over 20 million Americans. Yet in 2022, over 25 million Americans still did not have health insurance (KFF). Being uninsured has been shown to lead to poorer health outcomes, limited preventative care, and increased risk of mortality (NILC). Uninsurance is also associated with poor economic outcomes and increases general costs for employers, taxpayers, health systems, and the general public (Commonwealth). For example, uncompensated care for those without insurance averaged over \$42 billion between 2015 and 2017 (KFF).

Losing insurance can happen for a multitude of reasons, such as job loss or a change in eligibility for public insurance programs. However, getting people reenrolled in insurance can be difficult due to lack of knowledge of available programs and financial assistance, high cost of insurance, and availability (e.g. coverage offered through employment) (KFF). Due to the high social and economic costs associated with being uninsured, state and federal governments, non-profit organizations, and other interested stakeholders have launched campaigns to raise awareness on financial assistance programs, tax credits, state-based Marketplace exchanges, and Medicaid eligibility (Commonwealth). Given that the uninsured population is made up of over 25 million people, targeting campaigns can save taxpayer dollars and increase the effectiveness of the programs.

https://www.kff.org/uninsured/issue-brief/key-facts-about-the-uninsured-population/

https://www.nilc.org/wp-content/uploads/2015/11/consequences-of-being-uninsured-2014-08.pdf

https://www.commonwealthfund.org/sites/default/files/documents/\_\_\_media_files_publications_in_the_literature_2003_jun_the_costs_and_consequences_of_being_uninsured_davis_consequences_itl_663_pdf.pdf

https://www.kff.org/uninsured/issue-brief/sources-of-payment-for-uncompensated-care-for-the-uninsured/

https://www.commonwealthfund.org/publications/issue-briefs/2022/oct/state-based-outreach-boosting-enrollment-uninsured

### Methodology

Using supervised machine learning techniques and data from the Survey of Income and Participation (SIPP), we developed a model to predict the likelihood that a person would lose health insurance in the course of a year. Such a predictive model can help state and federal policymakers and other interested stakeholders target outreach and enrollment activities For example, it may be in a state's best interest to target enrollment campaigns for public insurance programs towards population groups of interest. As discussed, reducing the uninsured population can reduce health care costs for states and the federal government.

## Data Sources

The Survey of Income and Program Participation (SIPP) is an extensive survey conducted by the U.S. Census Bureau. It contains data on income, labor force participation, social program participation and eligibility, and general demographic characteristics. We are using the SIPP given its breadth, detail, and inclusion of health insurance status. We are using data from the year 2019, which was the last full year before the start of the COVID-19 pandemic and three full years of continuous eligibility in Medicaid. Using data after 2019 would not allow us to accurately examine churn. It is important to note that survey parti

Survey participants provide data for each month in the preceding calendar year at the time of the interview. Because of this detail, observations are on the person-month level, meaning there could be 12 observations for a single person for a given variable. Household-level questions are copied across all members of the household.

```{r}

library(tidyverse)
library(haven)
library(data.table)
library(readxl)
library(lubridate)

```

### Reading in Data

```{r, cache=TRUE, cache.id="data_pull"}

#initial pull of data
data_2018 <- fread("data/pu2018.csv", 
                   sep = "|",
                   showProgress = TRUE) %>% 
    select(-starts_with("A")) # these are status flags of all variables

data_2018 <- data_2018 %>% 
   #make unique ID for each respondent
  mutate(unique_id = paste(SSUID,PNUM))
  

#filtering by one month to have unique set of individuals with demographics
#data_2019_jan <- data_2018 %>%
 # select(-starts_with("A")) %>%
  # only include those that had medicaid
 # filter(RPUBTYPE2 == 1) %>% 
  # create unique identifier record
 #  mutate(unique_id = paste(SSUID,PNUM)) %>% 
#  distinct(unique_id)

```

### Adding the variable "lost_medicaid_coverage" to the January filtered dataset - SKIP

```{r}

#processing outcome variable - individuals covered by medicaid that experienced a gap in coverage during 2019
lost_medicaid_detail <- data_2018 %>%
  
  select(SPANEL,SSUID,SWAVE,PNUM,MONTHCODE,RHLTHMTH,RPUBTYPE2) %>% 
  
    #make unique ID for each respondent
  mutate(unique_id = paste(SSUID,PNUM))

#creating variables to assess if someone lost medicaid from one quarter to the next
lost_medicaid_prep <- lost_medicaid_detail %>% 
  arrange(unique_id,MONTHCODE) %>% 
  group_by(unique_id) %>% 
    mutate(
      #recode health insurance bulean to be "no_insurance"
      no_insurance = case_when(
        RHLTHMTH == 2 ~ 1, #had no coverage whatsoever
        RHLTHMTH == 1 ~ 0 #had coverage
      ),
      #recode medicaid bulean to be "medicaid"
      medicaid = case_when(
        RPUBTYPE2 == 1 ~ 1, #had medicaid specifically
        RPUBTYPE2 == 2 ~ 0 #didn't have medicaid
      ),
      
      #create field of "medicaid_last_month" for each observation
      medicaid_last_month = lag(medicaid),
      
      #create variable adding "no_insurance" & "medicaid" so that values that
      # = 2 mean someone experienced a lag in medicaid
      lost_medicaid = medicaid_last_month + no_insurance) %>% 
    filter(lost_medicaid == 2) 
      
      lost_medicaid = case_when(
        lost_medicaid == 2 ~ 1,
        lost_medicaid < 2 ~ 0
      )
      
      #rename month columns
      month = case_when(
        MONTHCODE == 1 ~ "January",
        MONTHCODE == 2 ~ "February",
        MONTHCODE == 3 ~ "March",
        MONTHCODE == 4 ~ "April",
        MONTHCODE == 5 ~ "May",
        MONTHCODE == 6 ~ "June",
        MONTHCODE == 7 ~ "July",
        MONTHCODE == 8 ~ "August",
        MONTHCODE == 9 ~ "September",
        MONTHCODE == 10 ~ "October",
        MONTHCODE == 11 ~ "November",
        MONTHCODE == 12 ~ "December")
    ) 
  
    
    #create data frame of unique individuals that had medicaid at some point of the year
      #will use to filter the lost_medicaid_prep 
      had_medicaid <-  lost_medicaid_prep %>% 
        pivot_wider(
      id_cols = unique_id, 
      names_from = month,
      values_from = medicaid) %>% 
        #column to assess if someone had medicaid
        mutate(
       months_medicaid = sum(January,February, March, April, May, June, July, August, September, October, November, December, na.rm = TRUE),
        months_medicaid = case_when(
          months_medicaid >= 1 ~ 1,
          months_medicaid < 1 ~ 0)
      ) %>% 
        select(unique_id,months_medicaid) %>% 
        #filter out the people that didn't have any medicaid at all
        filter(months_medicaid == 1)
      
      
    #filter main data frame to only include individuals that 
      #had medicaid at some point of the year
      data_2019_jan <- had_medicaid %>% 
        left_join(x = had_medicaid,y = data_2019_jan,by = "unique_id")

      
      #GO back to lost_medicaid table to filter out those that never had medicaid to lose
      lost_medicaid <- had_medicaid %>% 
            left_join(x = had_medicaid, y = lost_medicaid,by = "unique_id") %>% 
      #remove \January column, since we are not looking at people who lost coverage in January
        #select(-January) %>%
    #Create new field that adds together each month, where values >0 means someone lost medicaid during the year
      mutate(
        medicaid_lag = sum(February, March, April, May, June, July, August, September, October, November, December, na.rm = TRUE),
        medicaid_lag = case_when(
          medicaid_lag >= 1 ~ 1,
          medicaid_lag < 1 ~ 0)
      )

#add in "lost medicaid" varaible to january dataset
 data_2019_jan <- data_2019_jan %>% 
        left_join(x = data_2019_jan,y = lost_medicaid,by = "unique_id")
 
 
 data_2019_jan %>% 
   group_by(medicaid_lag) %>% 
   summarize(n())
 
```

#Insurance Loss Coding

```{r}
#processing outcome variable - individuals covered by medicaid that experienced a gap in coverage during 2019
lost_insurance_detail <- data_2018 %>%
  
  select(SPANEL,SSUID,SWAVE,PNUM,MONTHCODE,RHLTHMTH) %>% 
  
    #make unique ID for each respondent
  mutate(unique_id = paste(SSUID,PNUM))

#creating variables to assess if someone lost medicaid from one quarter to the next
lost_insurance_prep <- lost_insurance_detail %>% 
  arrange(unique_id,MONTHCODE) %>% 
  group_by(unique_id) %>% 
    mutate(
      #recode health insurance bulean to be "no_insurance"
      no_insurance = case_when(
        RHLTHMTH == 2 ~ 1, #had no coverage whatsoever
        RHLTHMTH == 1 ~ 0 #had coverage
      ),
     
      #create field of "no_insurance_last_month" for each observation
      no_insurance_last_month = lag(no_insurance),
      
      #create variable subtracting no_insurace and no_insurance last month
      # values will = 1 when they had insurance last month,  but didn't this
      lost_insurance = no_insurance - no_insurance_last_month,
     
      insurance_gap = case_when(
        lost_insurance > 0  ~ 1,
        lost_insurance <= 0 ~ 0),
     
      #rename month columns
      month = case_when(
        MONTHCODE == 1 ~ "January",
        MONTHCODE == 2 ~ "February",
        MONTHCODE == 3 ~ "March",
        MONTHCODE == 4 ~ "April",
        MONTHCODE == 5 ~ "May",
        MONTHCODE == 6 ~ "June",
        MONTHCODE == 7 ~ "July",
        MONTHCODE == 8 ~ "August",
        MONTHCODE == 9 ~ "September",
        MONTHCODE == 10 ~ "October",
        MONTHCODE == 11 ~ "November",
        MONTHCODE == 12 ~ "December")
    )
  
    
    #create data frame of unique individuals that had medicaid at some point of the year
      #will use to filter the lost_medicaid_prep 
      insurance_gap <-  lost_insurance_prep %>% 
        pivot_wider(
      id_cols = unique_id, 
      names_from = month,
      values_from = insurance_gap) %>% 
        #column to assess if someone had medicaid
        mutate(
       month_of_insurance_loss = sum(January,February, March, April, May, June, July, August, September, October, November, December, na.rm = TRUE),
        insurance_gap = case_when(
          month_of_insurance_loss > 0 ~ 1,
          month_of_insurance_loss < 1 ~ 0)
        )
    
      data_2018_final <- insurance_gap %>% 
        left_join(
          x = .,
          y = data_2018,
          by = "unique_id"
        ) %>% 
         distinct(unique_id, .keep_all = TRUE)
      
    #filter main data frame to only include individuals that 
      #had medicaid at some point of the year
      data_2019_jan <- had_medicaid %>% 
        left_join(x = had_medicaid,y = data_2019_jan,by = "unique_id")

      #GO back to lost_medicaid table to filter out those that never had medicaid to lose
      lost_medicaid <- had_medicaid %>% 
            left_join(x = had_medicaid, y = lost_medicaid,by = "unique_id") %>% 
      #remove \January column, since we are not looking at people who lost coverage in January
        #select(-January) %>%
    #Create new field that adds together each month, where values >0 means someone lost medicaid during the year
      mutate(
        medicaid_lag = sum(February, March, April, May, June, July, August, September, October, November, December, na.rm = TRUE),
        medicaid_lag = case_when(
          medicaid_lag >= 1 ~ 1,
          medicaid_lag < 1 ~ 0)
      )

#add in "lost medicaid" variable to january data set
 data_2019_jan <- data_2019_jan %>% 
        left_join(x = data_2019_jan,y = lost_medicaid,by = "unique_id")
 
 
insurance_gap %>% 
   group_by(insurance_gap) %>% 
   summarize(n())
 
```

```{r}

# tibble of indicator variables for state eligibility rules of interest
state_eligibility_rules <- read_excel("state_eligibility_rules.xlsx")

# tibble of variables where every single value is missing (we can drop these)
missing_vars <- data_2019 %>%
  summarise_all(~all(is.na(.))) %>%
  gather(variable, is_missing) %>%
  filter(is_missing) %>% 
  mutate(
  
  )

```

## Exploratory Data Analysis

### missingness (Akbar)

-   describe why we are leaving missinging as is, since they did imputation on thier own
-   explain missing variables in olivia's data

### correlation (Alicia)

```{r}
#| message: false
#| warning: false

# evaluating correlation
numeric_predictors <- data_2018_final %>%
  select(where(is.numeric))

# Calculate correlation matrix
correlation_matrix <- cor(numeric_predictors)

# Filter correlations above 0.5
non_response_correlations <- correlation_matrix["insurance_gap", ]

# Filter correlations greater than 0.5 or less than -0.5
significant_correlations <- non_response_correlations[abs(non_response_correlations) > 0.5]

significant_correlations <- significant_correlations[!is.na(significant_correlations)]

# Print the significant correlations
print(significant_correlations)



# Calculate phi coefficient
phi_coefficient <- data_2018_final %>% 
  cor(.$insurance_gap,.$October,use = "pairwise.complete.obs")

# Print the phi coefficient
print(phi_coefficient)


# Load the vcd package for Cramér's V calculation
library(vcd)

# Create a contingency table for two categorical variables
cont_table <- table(categorical_variable1, categorical_variable2)

# Calculate Cramér's V
cramers_v <- assocstats(cont_table)$cramer

# Create a table to display the results
results <- data.frame(
  Variable1 = "Categorical_Variable_1",
  Variable2 = "Categorical_Variable_2",
  Cramers_V = cramers_v
)

# Print the results
print(results)


```

### explore categorical variables of interest (Alicia - depending on Aaron's response)

-   review of categorical variables and see if there is anything crazy

### explore the distribution of outcome variable

-   look at what month had the most one's

### how do we decide what variables to drop?

-   explain highly correlated variables and

## Predictive Modeling

-   Describing the selection of variables

```{r}

## Alicia's feature engineering example for the random forest model from assignment 7 

rf_rec <- recipe(non_return_rate ~ ., training) %>% 
  ## remove categorical variables with many categories
    update_role(state_name, county_name,low_response_score,gidtr, 
                 pct_tea_update_leave_cen_2010, new_role = "id") %>%
      step_rm(has_role("id")) %>%
  ## impute missing values
  step_impute_mean(all_numeric_predictors()) 
 
```

-   see if any variables are 100% missing once we drop to Medicaid and January
-   look out for allocation flags (if it was imputed), status flags all start with A
-   consider dropping and picking key variables in each issue area
-   seam mismatch

## Analyzing Results

-   precision versus accuracy - justify error metric - Akbar
-   Variable Important

## Conclusions and Limitations

-   Conclusions and limitations text
